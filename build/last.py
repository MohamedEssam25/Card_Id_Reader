
# This file was generated by the Tkinter Designer by Parth Jadhav
# https://github.com/ParthJadhav/Tkinter-Designer

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tkinter.filedialog import askdirectory, askopenfilename
from pathlib import Path
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import cv2
import pytesseract
import numpy as np
from tkinter.filedialog import askdirectory, askopenfilename
# from tkinter import *
# Explicit imports to satisfy Flake8
from tkinter import Tk, Canvas, Entry, Text, Button, PhotoImage

from tkinter import Tk, Canvas, Button, PhotoImage, Label
from tkinter.filedialog import askdirectory, askopenfilename
from pathlib import Path
OUTPUT_PATH = Path(__file__).parent
ASSETS_PATH = OUTPUT_PATH / Path(r"C:\Users\hp\Desktop\project_deep\deep_project\build\assets\frame0") #اكتب المسار الملف عندك صح


def relative_to_assets(path: str) -> Path:
    return ASSETS_PATH / Path(path)


window = Tk()
window.title("Card Id Detect")
window.geometry("627x536")
window.configure(bg = "#ED3333")

class Ai:
    def __init__(self , alg=None,dat=None,imj=None):
        self.alg=alg
        self.dat=dat
        self.imj=imj
        
    def browse_imj(self):
        self.imj = askopenfilename(filetypes=[("Image files", "*.png;*.jpg;*.jpeg;*.bmp")])
        imagee_name = Path(self.imj).name
        x=self.imj.split(':')
        y=':/'.join(x)
        self.imj=y
        print(self.imj)
        label_imagee.config(text=imagee_name)
    
    def browse_algo(self):
        self.algo = askopenfilename(filetypes=[("PTH files", "*.pth")])
        algo_name = Path(self.algo).name
        xx=self.algo.split(':')
        yy=':/'.join(xx)
        self.algo=yy
        print(self.algo)
        label_done.config(text="done")
        label_algor.config(text=algo_name)
    def browse_dat(self):
        # image_name = Path(selected_image_path).name
        self.dat=askdirectory()
        image_name = Path(self.dat).name
        xxx=self.dat.split(':')
        yyy=':/'.join(xxx)
        self.dat=yyy
        print(self.dat)
        label_folder.config(text=image_name)


    def train(self):
        #data_dir = "data"  
        train_dir = f"{self.dat}/test"
        val_dir = f"{self.dat}/val"

        transform = transforms.Compose([
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

        # load data
        train_data = datasets.ImageFolder(train_dir, transform=transform)
        val_data = datasets.ImageFolder(val_dir, transform=transform)

        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)

        # build model
        class SimpleCNN(nn.Module):
            def __init__(self, num_classes=2):
                super(SimpleCNN, self).__init__()
                self.conv_layers = nn.Sequential(
                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(kernel_size=2, stride=2)
                )
                self.fc_layers = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(64 * 32 * 32, 128),
                    nn.ReLU(),
                    nn.Dropout(0.5),
                    nn.Linear(128, num_classes)
                )

            def forward(self, x):
                x = self.conv_layers(x)
                x = self.fc_layers(x)
                return x

        # class number
        num_classes = 2 
        model = SimpleCNN(num_classes=num_classes)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):
            for epoch in range(epochs):
                model.train()
                train_loss = 0.0
                for images, labels in train_loader:
                    images, labels = images.to(device), labels.to(device)

                    outputs = model(images)
                    loss = criterion(outputs, labels)

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    train_loss += loss.item()

                print(f"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss/len(train_loader):.4f}")

                # evaluate model
                model.eval()
                val_loss = 0.0
                correct = 0
                total = 0
                with torch.no_grad():
                    for images, labels in val_loader:
                        images, labels = images.to(device), labels.to(device)
                        outputs = model(images)
                        loss = criterion(outputs, labels)
                        val_loss += loss.item()

                        _, predicted = torch.max(outputs, 1)
                        correct += (predicted == labels).sum().item()
                        total += labels.size(0)

                print(f"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%")

        #train_model
        train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)

        torch.save(model.state_dict(), "card_classifier_new.pth")
        print("done")
        label_trained.config(text="Trained Succefully")


    def extract_id(self):
        pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        image = cv2.imread(self.imj)

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # إذا تم اكتشاف وجه، تحديد مكان البطاقة
        for (x, y, w, h) in faces:
            cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)

            # تحديد مكان البطاقة بناءً على مكان الوجه
            card_x1 = x
            card_y1 = y
            expansion_factor = 5
            card_x2 = min(x + int(expansion_factor * w), image.shape[1])
            card_y2 = y + int(2.5 * h)

            card_image = image[card_y1:card_y2, card_x1:card_x2]

        img = cv2.cvtColor(card_image, cv2.COLOR_BGR2GRAY)

        height, width = img.shape
        bottom_cut = int(height * 0.75)
        left_cut = int(width * 0.3)
        roi = img[bottom_cut:, left_cut:]

        ret, thresh1 = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)
        ret, thresh2 = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY_INV)
        ret, thresh3 = cv2.threshold(roi, 120, 255, cv2.THRESH_TRUNC)
        ret, thresh4 = cv2.threshold(roi, 120, 255, cv2.THRESH_TOZERO)
        ret, thresh5 = cv2.threshold(roi, 120, 255, cv2.THRESH_TOZERO_INV)

        custom_config = r'--oem 3 --psm 6'
        texts = [
            pytesseract.image_to_string(thresh1, lang="ara_number_id"),
            pytesseract.image_to_string(thresh2, lang="ara_number_id"),
            pytesseract.image_to_string(thresh3, lang="ara_number_id"),
            pytesseract.image_to_string(thresh4, lang="ara_number_id"),
            pytesseract.image_to_string(thresh5, lang="ara_number_id")
        ]

        print("Processing extracted numbers:")
        for text in texts:
            cleaned_text = text.replace(" ", "")  # إزالة المسافات
            numbers = [cleaned_text[i:i+14] for i in range(0, len(cleaned_text), 14) if len(cleaned_text[i:i+14]) == 14]
            for number in numbers:
                print("Extracted 14-digit number:", number)

        print("\n*** Results specifically from Trunc_Filter ***")
        cleaned_text = texts[2].replace(" ", "")
        numbers = [cleaned_text[i:i+14] for i in range(0, len(cleaned_text), 14) if len(cleaned_text[i:i+14]) == 14]
        for number in numbers:
            print("Id from Trunc Filter ", number)
            label_idd.config(text=number)
        cv2.imshow("Original ROI", roi)
        cv2.waitKey(0)
        cv2.destroyAllWindows()



    def check_card(self):
        class SimpleCNN(nn.Module):
            def __init__(self, num_classes=2):
                super(SimpleCNN, self).__init__()
                self.conv_layers = nn.Sequential(
                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(kernel_size=2, stride=2)
                )
                self.fc_layers = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(64 * 32 * 32, 128),
                    nn.ReLU(),
                    nn.Dropout(0.5),
                    nn.Linear(128, num_classes)
                )

            def forward(self, x):
                x = self.conv_layers(x)
                x = self.fc_layers(x)
                return x
        #load model
        num_classes = 2
        model = SimpleCNN(num_classes=num_classes)
        model.load_state_dict(torch.load(self.algo))
        model.eval()

        transform = transforms.Compose([
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

        # image_path = r"test\swe\27.jpg"  
        image = Image.open(self.imj)
        image_tensor = transform(image).unsqueeze(0)  

        # predict
        with torch.no_grad():
            output = model(image_tensor)
            _, predicted = torch.max(output, 1)

            if predicted.item() == 0:
                print("this card")
                label_cardd.config(text="This A Card!")
                test.extract_id()
            else:
                print("this no card")
                label_cardd.config(text="This NO Card ^.^")

    def show(self):
        imggg=cv2.imread(self.imj)
        imgg=cv2.resize(imggg,(1200,650))
        cv2.imshow("Test",imgg)
        cv2.waitKey(0)
        cv2.destroyAllWindows()



test=Ai()











canvas = Canvas(
    window,
    bg = "#ED3333",
    height = 536,
    width = 627,
    bd = 0,
    highlightthickness = 0,
    relief = "ridge"
)

canvas.place(x = 0, y = 0)
canvas.create_text(
    215.0,
    69.0,
    anchor="nw",
    text="Traning Algorthim",
    fill="#000000",
    font=("Inter Bold", 20 * -1)
)

canvas.create_text(
    36.0,
    117.0,
    anchor="nw",
    text="choose algorthim(.pth)",
    fill="#000000",
    font=("Inter SemiBold", 16 * -1)
)

canvas.create_text(
    433.0,
    117.0,
    anchor="nw",
    text="choose dataset",
    fill="#000000",
    font=("Inter SemiBold", 16 * -1)
)

button_image_1 = PhotoImage(
    file=relative_to_assets("button_1.png"))
button_1 = Button(
    image=button_image_1,
    borderwidth=0,
    highlightthickness=0,
    command=lambda: test.browse_algo(),
    relief="flat"
)
button_1.place(
    x=44.0,
    y=145.0,
    width=150.0,
    height=35.0
)

label_algor = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 14))
label_algor.place(x=44.0, y=180.0)

button_image_2 = PhotoImage(
    file=relative_to_assets("button_2.png"))
button_2 = Button(
    image=button_image_2,
    borderwidth=0,
    highlightthickness=0,
    command=lambda: test.browse_dat(),
    relief="flat"
)
button_2.place(
    x=418.0,
    y=145.0,
    width=150.0,
    height=35.0
)
label_folder = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 12))
label_folder.place(x=470.0, y=180.0)

button_image_3 = PhotoImage(
    file=relative_to_assets("button_3.png"))
button_3 = Button(
    image=button_image_3,
    borderwidth=0,
    highlightthickness=0,
    command=lambda: test.train(),
    relief="flat"
)
button_3.place(
    x=418.0,
    y=210.0,
    width=150.0,
    height=35.0
)

label_trained = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 16))
label_trained.place(x=430.0, y=250)

label_done = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 14))
label_done.place(x=255.0, y=230)

button_image_4 = PhotoImage(
    file=relative_to_assets("button_4.png"))
button_4 = Button(
    image=button_image_4,
    borderwidth=0,
    highlightthickness=0,
    command=lambda: test.browse_imj(),
    relief="flat"
)
button_4.place(
    x=200.0,
    y=298.0,
    width=150.0,
    height=35.0
)

label_imagee = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 16))
label_imagee.place(x=245.0, y=335)

button_image_5 = PhotoImage(
    file=relative_to_assets("button_5.png"))
button_5 = Button(
    image=button_image_5,
    borderwidth=0,
    highlightthickness=0,
    command=lambda: test.check_card(),
    relief="flat"
)
button_5.place(
    x=200.0,
    y=367.0,
    width=150.0,
    height=35.0
)

canvas.create_text(
    176.0,
    11.0,
    anchor="nw",
    text="Card Id Reader",
    fill="#000000",
    font=("Inter MediumItalic", 36 * -1)
)

# canvas.create_text(
#     236.0,
#     242.0,
#     anchor="nw",
#     text="done or not",
#     fill="#000000",
#     font=("Inter SemiBold", 16 * -1)
# )

canvas.create_text(
    237.0,
    267.0,
    anchor="nw",
    text="choose card",
    fill="#000000",
    font=("Inter SemiBold", 16 * -1)
)

# canvas.create_text(
#     194.0,
#     437.0,
#     anchor="nw",
#     text="sucess or is not a card",
#     fill="#000000",
#     font=("Inter SemiBold", 16 * -1)
# )
label_cardd = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 16))
label_cardd.place(x=210.0, y=420)

# canvas.create_text(
#     249.0,
#     468.0,
#     anchor="nw",
#     text="the id",
#     fill="#000000",
#     font=("Inter SemiBold", 16 * -1)
# )
label_idd = Label(window, text="", bg="#ED3333", fg="#000000", font=("Inter", 16))
label_idd.place(x=210.0, y=460)

canvas.create_text(
    2.0,
    506.0,
    anchor="nw",
    text="Eng/Omar Elnahas",
    fill="#000000",
    font=("Inter", 20 * -1)
)
button_image_6 = PhotoImage(
    file=relative_to_assets("button_6.png"))
button_6 = Button(
    image=button_image_6,
    borderwidth=0,
    highlightthickness=0,
    command=lambda: test.show(),
    relief="flat"
)
button_6.place(
    x=403.0,
    y=298.0,
    width=150.0,
    height=35.0
)
# canvas.create_text(
#     423.0,
#     252.0,
#     anchor="nw",
#     text="Trained Succsefly",
#     fill="#000000",
#     font=("Inter Bold", 16 * -1)
# )
window.resizable(False, False)
window.mainloop()

